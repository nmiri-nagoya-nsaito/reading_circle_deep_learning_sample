{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5章 誤差逆伝播法\n",
    "* 前章では重みパラメータの勾配（重みパラメータに関する損失関数の勾配）を数値微分で決定した．\n",
    "* 数値微分は簡単だが計算に時間がかかる\n",
    "* 本章では重みパラメータの効率良い計算法として「誤差逆伝播法」について学ぶ\n",
    "* 誤差逆伝播法を理解する方法\n",
    "  * 数式による方法：一般的な方法．厳密で簡潔．\n",
    "  * 計算グラフ（computational graph）による方法：視覚的，分かりやすい．\n",
    "    * [Hacker's guide to Neural Networks](http://karpathy.github.io/neuralnets/)\n",
    "    * [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io)\n",
    "\n",
    "## 5.1 計算グラフ\n",
    "\n",
    "* 計算グラフとは，計算の過程をグラフで表したもの\n",
    "  * グラフとは，複数のノードとエッジ（ノード間を結ぶ直線）によって表現される，データ構造としてのグラフ\n",
    "\n",
    "### 5.1.1 計算グラフで解く\n",
    "\n",
    "問1：太郎くんはスーパーで1個100円のリンゴを2個買いました．支払う金額を求めなさい．ただし，消費税が10％適用されるものとします．\n",
    "\n",
    "* 計算グラフはノードと矢印で計算過程を表す．\n",
    "* ノードは○で表記し，○の中に演算の内容を書く\n",
    "* 計算の途中結果を矢印の上部に書くことで，ノードごとの計算結果が左から右へ伝わるように表す\n",
    "\n",
    "<img src=\"./fig5_1.png\">\n",
    "\n",
    "```\n",
    "# http://viz-js.com/\n",
    "digraph G {\n",
    "    rankdir=LR;\n",
    "    node [shape=circle]\n",
    "    n0 [label=\"リンゴ\"]\n",
    "    n1 [label=\"×2\"]\n",
    "    n2 [label=\"×1.1\"]\n",
    "    n3 [label=\"合計\"]\n",
    "\n",
    "    n0 -> n1 [label=\"100\"]\n",
    "    n1 -> n2 [label=\"200\"]\n",
    "    n2 -> n3 [label=\"220\"]\n",
    "}\n",
    "```\n",
    "\n",
    "* 最初にリンゴの100円が「×2」ノードへ流れ，200円になって次のノードの伝達される\n",
    "* その200円が「×1.1」ノードへ流れ，220円になる\n",
    "* この計算グラフの結果から答えは220円になる\n",
    "\n",
    "#### 別の書き方\n",
    "\n",
    "<img src=\"./fig5_2.png\">\n",
    "\n",
    "```\n",
    "# http://viz-js.com/\n",
    "digraph G {\n",
    "    rankdir=LR;\n",
    "    node [shape=circle]\n",
    "    n0 [label=\"リンゴ\"]\n",
    "    n01 [label=\"リンゴ\\nの個数\"]\n",
    "    n1 [label=\"×\"]\n",
    "    n11 [label=\"消費税\"]\n",
    "    n2 [label=\"×\"]\n",
    "    n3 [label=\"合計\"]\n",
    "\n",
    "    n0 -> n1 [label=\"100\"]\n",
    "    n01 -> n1 [label=\"2\"]\n",
    "    n1 -> n2 [label=\"200\"]\n",
    "    n11 -> n2 [label=\"1.1\"]\n",
    "    n2 -> n3 [label=\"220\"]\n",
    "}\n",
    "```\n",
    "\n",
    "問2：太郎くんはスーパーでリンゴを2個，みかんを3個買いました．リンゴは1個100円，みかんは1個150円です．消費税が10％かかるものとして，支払う金額を求めなさい．\n",
    "\n",
    "<img src=\"./fig5_3.png\">\n",
    "\n",
    "```\n",
    "# http://viz-js.com/\n",
    "digraph G {\n",
    "    rankdir=LR;\n",
    "    node [shape=circle]\n",
    "    n00 [label=\"リンゴ\"]\n",
    "    n01 [label=\"リンゴ\\nの個数\"]\n",
    "    n03 [label=\"みかん\\nの個数\"]\n",
    "    n02 [label=\"みかん\"]\n",
    "\n",
    "    n10 [label=\"×\"]\n",
    "    n11 [label=\"×\"]\n",
    "    \n",
    "    n20 [label=\"+\"]\n",
    "    n21 [label=\"消費税\"]\n",
    "\n",
    "    n3 [label=\"×\"]\n",
    "    n4 [label=\"合計\"]\n",
    "\n",
    "    n00 -> n10 [label=\"100\"]\n",
    "    n01 -> n10 [label=\"2\"]\n",
    "    n02 -> n11 [label=\"150\"]\n",
    "    n03 -> n11 [label=\"3\"]\n",
    "    \n",
    "    n10 -> n20 [label=\"200\"]\n",
    "    n11 -> n20 [label=\"450\"]\n",
    "\n",
    "    n20 -> n3 [label=\"650\"]\n",
    "    n21 -> n3 [label=\"1.1\"]\n",
    "    n3 -> n4 [label=\"715\"]\n",
    "}\n",
    "```\n",
    "\n",
    "#### 計算グラフまとめ\n",
    "\n",
    "* 計算グラフを使って問題を解く流れ\n",
    "    1. 計算グラフを構築する\n",
    "    2. 計算グラフ上で計算を左から右へ進める（順伝播 forward propagation という）   \n",
    "\n",
    "### 5.1.2 局所的な計算\n",
    "\n",
    "* 計算グラフの特徴は「局所的な計算」を伝播することにより最終的な結果を得ることができる点\n",
    "  * 局所的とは「自分（ノード）に関係する小さな範囲」ということ．それ以外は気にしない\n",
    "  * 局所的な計算とは「自分（ノード）への入力だけからその結果を出力する」ということ\n",
    "* 全体では複雑な計算であったとしても，分割して単純な局所的計算の集まりにでき，それぞれは個々の計算に集中できる\n",
    "\n",
    "### 5.1.3 なぜ計算グラフで解くのか？\n",
    "\n",
    "* 計算グラフの利点\n",
    "  * 局所的な計算．分割して個々の問題を単純にする．\n",
    "  * 途中の計算結果を保持できる\n",
    "  * **逆方向の伝播によって「微分」を効率良く計算できる**\n",
    "\n",
    "* ここで問1の場合での微分とは何かを考えてみる\n",
    "  * 合計をりんごの値段で微分する場合（つまり，「りんごの値段に関する合計金額の微分」を求める）\n",
    "  * 記号で表現すると「合計金額を$L$,りんごの値段を$x$とするとき$\\frac{\\partial L}{\\partial x}$を求める」ことになる\n",
    "* 微分は逆方向の伝播で計算することができる\n",
    "  * 逆伝播は逆向きの矢印で表現する\n",
    "  * 逆伝播は局所的な微分を表す\n",
    "  * この図の場合，りんごを指す矢印の数値は2.2になる．これは微分が2.2であることを表す．\n",
    "    * つまり，りんごが1円値上がりしたら支払い金額は2.2円増える\n",
    "\n",
    "<img src=\"./fig5_4.png\">\n",
    "\n",
    "```\n",
    "digraph G {\n",
    "    rankdir=LR;\n",
    "    node [shape=circle]\n",
    "    n0 [label=\"リンゴ\"]\n",
    "    n01 [label=\"リンゴ\\nの個数\"]\n",
    "    n1 [label=\"×\",color=\"gray\"]\n",
    "    n11 [label=\"消費税\"]\n",
    "    n2 [label=\"×\",color=\"gray\"]\n",
    "    n3 [label=\"合計\"]\n",
    "\n",
    "    n0 -> n1 [label=\"100\",color=\"gray\"]\n",
    "    n01 -> n1 [label=\"2\",color=\"gray\"]\n",
    "    n1 -> n2 [label=\"200\",color=\"gray\"]\n",
    "    n11 -> n2 [label=\"1.1\",color=\"gray\"]\n",
    "    n2 -> n3 [label=\"220\",color=\"gray\"]\n",
    "\n",
    "    n3 -> n2 [label=\"1\",style=\"bold\",color=\"red\"]\n",
    "    n2 -> n1 [label=\"1.1\",style=\"bold\",color=\"red\"]\n",
    "    n1 -> n0 [label=\"2.2\",style=\"bold\",color=\"red\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 連鎖律\n",
    "\n",
    "* 「局所的な微分」を伝達する原理は**連鎖率(chain rule)**による\n",
    "\n",
    "### 5.2.1 計算グラフの逆伝播\n",
    "\n",
    "#### 逆伝播の計算\n",
    "\n",
    "* 信号Eに，関数$f=y(x)$の微分$\\frac{\\partial y}{\\partial x}$を乗算して前のノードへ渡す\n",
    "* これで微分値が効率よく求められる理由は連鎖率の原理にある(次節で説明)\n",
    "\n",
    "<img src=\"fig5_5.png\">\n",
    "\n",
    "### 5.2.2 連鎖律とは\n",
    "\n",
    "#### 合成関数\n",
    "\n",
    "* 合成関数とは，複数の関数によって構成される関数のこと\n",
    "  * たとえば $z={(x+y)}^2$ という式は次の2つの式で構成される\n",
    "    * $z=t^2$\n",
    "    * $t=x+y$\n",
    "\n",
    "#### 連鎖律\n",
    "\n",
    "連鎖律とは，合成関数の微分についての性質のこと\n",
    "\n",
    "#### 連鎖律の原理\n",
    "\n",
    "* ある関数が合成関数で表される場合，その合成関数の微分は，合成関数を構成するそれぞれの関数の微分の席によって表すことができる\n",
    "  * $\\frac{\\partial z}{\\partial x}$ は$\\frac{\\partial z}{\\partial t}$と$\\frac{\\partial t}{\\partial x}$の席で表すことができるということ\n",
    "$$\\frac{\\partial z}{\\partial x} \n",
    "= \\frac{\\partial z}{\\partial t}\\frac{\\partial t}{\\partial x}$$\n",
    "先の例では$\\frac{\\partial z}{\\partial t}=2t$,$\\frac{\\partial t}{\\partial x}=1$が解析的に得られたため\n",
    "$$\\frac{\\partial z}{\\partial x} = 2(x+y)$$\n",
    "\n",
    "### 5.2.3 連鎖律と計算グラフ\n",
    "\n",
    "$t=(x+y)^2$をノードで表してみる\n",
    "\n",
    "<img src=\"fig5_6.png\">\n",
    "\n",
    "* 逆伝播は右から左へと信号が伝播する\n",
    "* 各ノードはそれまでの偏微分の積を受け取り，それに自ノードの偏微分を積算して次（前段）のノードへ送る\n",
    "* 自ノードの偏微分を積算することで，最終出力を自ノードの入力で偏微分した結果が得られることになる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 逆伝播\n",
    "\n",
    "### 5.3.1 加算ノードの逆伝播\n",
    "\n",
    "$\\frac{\\partial z}{\\partial x}=1$, $\\frac{\\partial z}{\\partial y}=1$であるため，上流から伝わった微分を$\\frac{\\partial L}{\\partial z}$とすると次のようになる．\n",
    "\n",
    "<img src=\"fig5_7.png\">\n",
    "\n",
    "つまり，加算ノードの逆伝播は入力の内容をそのまま出力するだけ．\n",
    "\n",
    "```\n",
    "digraph G {\n",
    "    rankdir=LR;\n",
    "    node [shape=circle]\n",
    "    n0 [label=\"\", color=\"none\"]\n",
    "    n01 [label=\"\", color=\"none\"]\n",
    "    n1 [label=\"+\",color=\"gray\"]\n",
    "    n2 [label=\"\",color=\"none\"]\n",
    "\n",
    "    { rank = same;\n",
    "        \"n0\", \"n01\";\n",
    "    }\n",
    "\n",
    "    n0 -> n1 [label=\"x\",color=\"gray\"]\n",
    "    n01 -> n1 [label=\"y\",color=\"gray\"]\n",
    "    n1 -> n2 [label=\"z\",color=\"gray\"]\n",
    "\n",
    "    n1 -> n0 [label=\"dL/dz・1 \",style=\"bold\",color=\"red\"]\n",
    "    n1 -> n01 [label=\"dL/dz・1 \",style=\"bold\",color=\"red\"]\n",
    "    n2 -> n1 [label=\"dL/dz\",style=\"bold\",color=\"red\"]\n",
    "}\n",
    "```\n",
    "\n",
    "### 5.3.2 乗算ノードの逆伝播\n",
    "\n",
    "$\\frac{\\partial z}{\\partial x}=y$, $\\frac{\\partial z}{\\partial y}=x$であるため，上流から伝わった微分を$\\frac{\\partial L}{\\partial z}$とすると次のようになる．\n",
    "\n",
    "<img src=\"fig5_8.png\">\n",
    "\n",
    "乗算ノードの逆伝播は入力の内容に入力をひっくり返した値を乗算して出力する．\n",
    "（多入力の乗算の場合は？2入力の乗算に分解すればいいということか）\n",
    "\n",
    "### 5.3.3 リンゴの例\n",
    "\n",
    "先のりんごとみかんの例について逆伝播をためしてみる．\n",
    "\n",
    "<img src=\"fig5_9.png\">\n",
    "\n",
    "```\n",
    "# http://viz-js.com/\n",
    "digraph G {\n",
    "    rankdir=LR;\n",
    "    node [shape=circle]\n",
    "    n00 [label=\"リンゴ\"]\n",
    "    n01 [label=\"リンゴ\\nの個数\"]\n",
    "    n03 [label=\"みかん\\nの個数\"]\n",
    "    n02 [label=\"みかん\"]\n",
    "\n",
    "    n10 [label=\"×\"]\n",
    "    n11 [label=\"×\"]\n",
    "\n",
    "    n20 [label=\"+\"]\n",
    "    n21 [label=\"消費税\"]\n",
    "\n",
    "    n3 [label=\"×\"]\n",
    "    n4 [label=\"合計\"]\n",
    "\n",
    "    { rank = same; \"n00\", \"n01\", \"n02\", \"n03\"; }\n",
    "    { rank = same; \"n10\", \"n11\"; }\n",
    "    { rank = same; \"n20\", \"n21\"; }\n",
    "    { rank = same; \"n3\"; }\n",
    "    { rank = sink; \"n4\"; }\n",
    "\n",
    "    n00 -> n10 [label=\"100\"]\n",
    "    n01 -> n10 [label=\"2\"]\n",
    "    n02 -> n11 [label=\"150\"]\n",
    "    n03 -> n11 [label=\"3\"]\n",
    "    n10 -> n20 [label=\"200\"]\n",
    "    n11 -> n20 [label=\"450\"]\n",
    "    n20 -> n3 [label=\"650\"]\n",
    "    n21 -> n3 [label=\"1.1\"]\n",
    "    n3 -> n4 [label=\"715\"]\n",
    "\n",
    "    n4 -> n3 [label=\"1\", color=\"red\", style=\"bold\"]\n",
    "    n3 -> n20 [label=\"1.1\", color=\"red\", style=\"bold\"]\n",
    "    n3 -> n21 [label=\"650\", color=\"red\", style=\"bold\"]\n",
    "    n20 -> n10 [label=\"1.1\", color=\"red\", style=\"bold\"]\n",
    "    n20 -> n11 [label=\"1.1\", color=\"red\", style=\"bold\"]\n",
    "    n10 -> n00 [label=\"2\", color=\"red\", style=\"bold\"]\n",
    "    n10 -> n01 [label=\"110\", color=\"red\", style=\"bold\"]\n",
    "    n11 -> n02 [label=\"3.3\", color=\"red\", style=\"bold\"]\n",
    "    n11 -> n03 [label=\"165\", color=\"red\", style=\"bold\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 単純なレイヤの実装\n",
    "\n",
    "### 5.4.1 乗算レイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 乗算レイヤの実装\n",
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x * y\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "        \n",
    "        return dx, dy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n"
     ]
    }
   ],
   "source": [
    "# 乗算レイヤを使ったりんごの例を計算してみる\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "# layer の定義\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2 110.00000000000001 200\n"
     ]
    }
   ],
   "source": [
    "# りんごの例で，逆伝播から微分を求めてみる\n",
    "# dapple_price, dtax はそれぞれ apple_price, tax の微分を表す\n",
    "dprice = 1\n",
    "\n",
    "# 呼び出す順番は forward の時と逆の順番で行う\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(dapple, dapple_num, dtax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 加算レイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 加算レイヤの実装\n",
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n"
     ]
    }
   ],
   "source": [
    "# りんごとみかんの買い物の例を実装する\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "# layer の定義\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price)\n",
    "price = mul_tax_layer.forward(all_price, tax)\n",
    "\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2 110.00000000000001 3.3000000000000003 165.0 1.1 1.1 1.1 650\n"
     ]
    }
   ],
   "source": [
    "# 微分を計算してみる\n",
    "\n",
    "dprice = 1\n",
    "\n",
    "# backword\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)\n",
    "\n",
    "print(dapple, dapple_num, dorange, dorange_num, dapple_price, dorange_price, dall_price, dtax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 活性化関数レイヤの実装\n",
    "\n",
    "### 5.5.1 ReLUレイヤ\n",
    "\n",
    "ReLU(Rectified Linear Unit) の式\n",
    "\n",
    "$$y = \\left\\{ \n",
    "    \\begin{array}{ll}\n",
    "        x & (x>0) \\\\\n",
    "        0 & (x \\leq 0) \\\\\n",
    "    \\end{array} \\right.\n",
    "$$\n",
    "ここで$y$を$x$で偏微分すると\n",
    "$$\\frac{\\partial y}{\\partial x} = \\left\\{ \n",
    "    \\begin{array}{ll}\n",
    "        1 & (x>0) \\\\\n",
    "        0 & (x \\leq 0) \\\\\n",
    "    \\end{array} \\right.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ReLUレイヤの実装\n",
    "# ここで forward および backward にはNumPyの配列が入力されることを想定する\n",
    "\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        # マスクされる要素のインデックスのみTrueでそれ以外はFalseのNumpy配列\n",
    "        self.mask = None\n",
    "    \n",
    "    # 入力xの要素のうち，0以下の要素のみ0にして出力する\n",
    "    def forward(self, x):\n",
    "        # 0以下の値を持つ要素のみTrueを持つ配列を作る\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        # doutの中で，マスクする要素のみ0にする．それ以外はそのままの値とする\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.2 Sigmoidレイヤ\n",
    "\n",
    "シグモイド関数の定義\n",
    "$$y=\\frac{1}{1+\\exp (-x)}$$\n",
    "\n",
    "およびその偏微分は次のようになる．\n",
    "$$\\frac{\\partial y}{\\partial x}=y^2\\exp(-x)$$\n",
    "\n",
    "この関数の計算グラフおよび微分を計算すると，次のようになる\n",
    "<img src=\"fig5_10.png\">\n",
    "出力$y$の$x$による偏微分の式は$x$と$y$のみからなるため，次のように計算グラフを簡略化できる\n",
    "<img src=\"fig5_11.png\">\n",
    "\n",
    "さらに式を変形する\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\frac{\\partial L}{\\partial y}y^2\\exp(-x) &=& \\frac{\\partial L}{\\partial y}\\frac{1}{(1+\\exp(-x))^2}\\exp(-x) \\\\\n",
    "&=& \\frac{\\partial L}{\\partial y}\\frac{1}{1+\\exp(-x)}\\frac{\\exp(-x)}{1+\\exp(-x)} \\\\\n",
    "&=& \\frac{\\partial L}{\\partial y}{y(1-y)} \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "つまり，Sigmoid関数の微分は順方向の出力値だけを使って計算することができる\n",
    "<img src=\"fig5_12.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sigmoidレイヤの実装\n",
    "# ここで forward および backward にはNumPyの配列が入力されることを想定する\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = 1/(1+np.exp(-x))\n",
    "        #　逆伝播のときに使えるよう記憶しておく\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Affine/Softmaxレイヤの実装\n",
    "\n",
    "### 5.6.1 Affineレイヤ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.2 バッチ版Affineレイヤ\n",
    "\n",
    "### 5.6.3 Softmax-with-Lossレイヤ\n",
    "\n",
    "## 5.7 誤差逆伝播法の実装\n",
    "\n",
    "### 5.7.1 ニューラルネットワークの学習の全体図\n",
    "\n",
    "### 5.7.2 誤差逆伝播法に対応したニューラルネットワークの実装\n",
    "\n",
    "### 5.7.3 誤差逆伝播法の勾配確認\n",
    "\n",
    "### 5.7.4 誤差逆伝播法を使った学習\n",
    "\n",
    "## 5.8 まとめ\n",
    "\n",
    "* 視覚的に計算の価値を表す計算グラフを学んだ\n",
    "* 計算グラフを用いてニューラルネットワークで行う逆誤差伝搬法を説明し，ニューラルネットワークで行う処理をレイヤという単位で実装した\n",
    "    * ReLUレイヤ，Softmax-with-Lossレイヤ，Affineレイヤ，Softmaxレイヤ\n",
    "    * レイヤにはforwardとbackwardというメソッドが実装されている\n",
    "    * データを順方向と逆方向に伝搬することで重みパラメータの勾配を効率的に求めることができる\n",
    "* レイヤによるモジュール化によりレイヤを自由に組み合わせることができ，好きなネットワークを簡単に作ることができる\n",
    "\n",
    "* 計算グラフを用いると計算過程を簡単に把握できる\n",
    "* 計算グラフのノードは局所的な計算により構成される．局所的な計算が全体の計算を構成する．\n",
    "* 計算グラフの順伝搬は通常の計算を行う．\n",
    "* 計算グラフの逆伝搬によって微分を求めることができる\n",
    "* ニューラルネットワークの構成要素をレイヤとして実装することで，勾配計算を効率的に求めることができる（逆誤差伝搬法）\n",
    "* 数値微分と逆誤差伝搬法の結果を比較することで，逆誤差伝搬法の実装に誤りがないことを確認することができる（勾配確認）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
